{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "20e94d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a9cc82d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "Epochs = 20\n",
    "classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7557d0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "t = transforms.Compose([transforms.ToTensor(),\n",
    "                       transforms.Lambda(lambda x : x.permute(1, 2, 0).reshape(-1))\n",
    "                       ])\n",
    "target_t = lambda label: F.one_hot(torch.tensor(label), num_classes=10)\n",
    "\n",
    "\n",
    "train_dataset = datasets.SVHN(root=\"./data\", split=\"train\", transform= t, target_transform=target_t, download=True)\n",
    "test_dataset = datasets.SVHN(root=\"./data\", split=\"test\", transform= t, target_transform=target_t, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b770c224",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f3274278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(next(iter(test_loader)))\n",
    "img = next(iter(test_loader))[0][3].reshape(32,32,3)\n",
    "label = next(iter(test_loader))[1][3]\n",
    "def visual(img):    \n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(15,5)\n",
    "\n",
    "    img = img.numpy()\n",
    "    im = ax.imshow(img, cmap=plt.cm.gray)\n",
    "    fig.colorbar(im)\n",
    "    ax.set_title(\"Image\")\n",
    "\n",
    "visual(img)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ea49f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model \n",
    "\n",
    "def define_model(trial):\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 4)\n",
    "    \n",
    "    layers = []\n",
    "    \n",
    "    in_features = 3 * 32 * 32\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(f\"n_units_layer{i}\", 256, 1024)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLu())\n",
    "        \n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, classes))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "    \n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "387b1a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    model = Network().to(device)\n",
    "    \n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    #training\n",
    "    for epoch in range(Epochs):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.type(torch.float32).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        #validation\n",
    "        model.eval()\n",
    "        total_corr = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(test_loader):\n",
    "                \n",
    "                data, target = data.to(device), target.type(torch.float32).to(device)\n",
    "                output = model(data)\n",
    "                pred = torch.argmax(output, dim=1)\n",
    "                \n",
    "                gt = torch.argmax(target, dim=1)\n",
    "                correct = torch.count_nonzero(pred == gt)\n",
    "                total_corr += correct\n",
    "        accuracy = (total_corr/len(test_dataset))\n",
    "        \n",
    "        trial.report(accuracy, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ecac23d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-13 16:39:29,215]\u001b[0m A new study created in memory with name: no-name-50074477-0f8f-4a4b-afb1-2290e43c24e0\u001b[0m\n",
      "\u001b[32m[I 2021-11-13 16:43:48,757]\u001b[0m Trial 0 finished with value: 0.5062615275382996 and parameters: {'optimizer': 'RMSprop', 'lr': 2.9028529000928725e-05}. Best is trial 0 with value: 0.5062615275382996.\u001b[0m\n",
      "\u001b[32m[I 2021-11-13 16:48:05,865]\u001b[0m Trial 1 finished with value: 0.6276505589485168 and parameters: {'optimizer': 'Adam', 'lr': 0.0030694612988594948}. Best is trial 1 with value: 0.6276505589485168.\u001b[0m\n",
      "\u001b[32m[I 2021-11-13 16:52:22,595]\u001b[0m Trial 2 finished with value: 0.1951444298028946 and parameters: {'optimizer': 'SGD', 'lr': 5.438961636729603e-05}. Best is trial 1 with value: 0.6276505589485168.\u001b[0m\n",
      "\u001b[32m[I 2021-11-13 16:56:41,104]\u001b[0m Trial 3 finished with value: 0.7272971868515015 and parameters: {'optimizer': 'Adam', 'lr': 0.000526320907706507}. Best is trial 3 with value: 0.7272971868515015.\u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:00:56,603]\u001b[0m Trial 4 finished with value: 0.5367624163627625 and parameters: {'optimizer': 'Adam', 'lr': 0.008241653441381962}. Best is trial 3 with value: 0.7272971868515015.\u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:01:09,542]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:01:22,373]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:01:35,240]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:02:14,014]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:02:26,861]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:06:35,735]\u001b[0m Trial 10 finished with value: 0.7293331027030945 and parameters: {'optimizer': 'Adam', 'lr': 0.0008127052057971569}. Best is trial 10 with value: 0.7293331027030945.\u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:10:42,707]\u001b[0m Trial 11 finished with value: 0.7051321268081665 and parameters: {'optimizer': 'Adam', 'lr': 0.0006910450815367325}. Best is trial 10 with value: 0.7293331027030945.\u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:14:45,489]\u001b[0m Trial 12 finished with value: 0.7018284797668457 and parameters: {'optimizer': 'Adam', 'lr': 0.001693996267619176}. Best is trial 10 with value: 0.7293331027030945.\u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:14:57,585]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:15:09,958]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:15:34,604]\u001b[0m Trial 15 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:19:43,257]\u001b[0m Trial 16 finished with value: 0.7255685329437256 and parameters: {'optimizer': 'Adam', 'lr': 0.0008055717054398512}. Best is trial 10 with value: 0.7293331027030945.\u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:19:55,039]\u001b[0m Trial 17 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:20:07,576]\u001b[0m Trial 18 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:20:32,750]\u001b[0m Trial 19 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:20:45,306]\u001b[0m Trial 20 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:24:51,758]\u001b[0m Trial 21 finished with value: 0.7552627325057983 and parameters: {'optimizer': 'Adam', 'lr': 0.0009683390435270988}. Best is trial 21 with value: 0.7552627325057983.\u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:25:03,864]\u001b[0m Trial 22 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:29:09,460]\u001b[0m Trial 23 finished with value: 0.7110479474067688 and parameters: {'optimizer': 'Adam', 'lr': 0.002308748121165588}. Best is trial 21 with value: 0.7552627325057983.\u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:31:09,433]\u001b[0m Trial 24 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:31:21,560]\u001b[0m Trial 25 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:31:33,726]\u001b[0m Trial 26 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:31:45,928]\u001b[0m Trial 27 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:31:58,024]\u001b[0m Trial 28 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:32:10,059]\u001b[0m Trial 29 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:32:22,286]\u001b[0m Trial 30 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:32:46,603]\u001b[0m Trial 31 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:33:10,810]\u001b[0m Trial 32 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:37:16,662]\u001b[0m Trial 33 finished with value: 0.7316379547119141 and parameters: {'optimizer': 'Adam', 'lr': 0.0006023740075188162}. Best is trial 21 with value: 0.7552627325057983.\u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:37:29,099]\u001b[0m Trial 34 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:37:41,452]\u001b[0m Trial 35 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:37:53,755]\u001b[0m Trial 36 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:38:05,966]\u001b[0m Trial 37 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:38:17,972]\u001b[0m Trial 38 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:39:06,939]\u001b[0m Trial 39 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:39:31,364]\u001b[0m Trial 40 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:39:43,738]\u001b[0m Trial 41 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:39:55,890]\u001b[0m Trial 42 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:40:08,066]\u001b[0m Trial 43 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:40:20,033]\u001b[0m Trial 44 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:40:32,076]\u001b[0m Trial 45 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:40:44,495]\u001b[0m Trial 46 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:40:56,807]\u001b[0m Trial 47 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:41:08,821]\u001b[0m Trial 48 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:41:45,530]\u001b[0m Trial 49 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:41:57,830]\u001b[0m Trial 50 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:42:10,006]\u001b[0m Trial 51 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:42:22,038]\u001b[0m Trial 52 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:42:34,295]\u001b[0m Trial 53 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:42:46,541]\u001b[0m Trial 54 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:42:58,800]\u001b[0m Trial 55 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:43:10,961]\u001b[0m Trial 56 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:43:23,061]\u001b[0m Trial 57 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:43:35,332]\u001b[0m Trial 58 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:43:47,877]\u001b[0m Trial 59 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:44:12,870]\u001b[0m Trial 60 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:48:20,470]\u001b[0m Trial 61 finished with value: 0.7418177723884583 and parameters: {'optimizer': 'Adam', 'lr': 0.001046398560447674}. Best is trial 21 with value: 0.7552627325057983.\u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:49:21,157]\u001b[0m Trial 62 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:49:45,278]\u001b[0m Trial 63 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:50:09,470]\u001b[0m Trial 64 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:50:21,277]\u001b[0m Trial 65 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:50:33,247]\u001b[0m Trial 66 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:51:09,744]\u001b[0m Trial 67 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:51:33,520]\u001b[0m Trial 68 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:51:45,545]\u001b[0m Trial 69 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:51:57,802]\u001b[0m Trial 70 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:52:09,865]\u001b[0m Trial 71 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:52:33,870]\u001b[0m Trial 72 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:52:45,911]\u001b[0m Trial 73 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:52:57,910]\u001b[0m Trial 74 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:57:01,139]\u001b[0m Trial 75 finished with value: 0.7497310638427734 and parameters: {'optimizer': 'Adam', 'lr': 0.0013772645995473315}. Best is trial 21 with value: 0.7552627325057983.\u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:57:13,303]\u001b[0m Trial 76 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:57:25,604]\u001b[0m Trial 77 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:57:37,999]\u001b[0m Trial 78 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:57:50,376]\u001b[0m Trial 79 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:58:02,826]\u001b[0m Trial 80 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:58:39,746]\u001b[0m Trial 81 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:58:52,280]\u001b[0m Trial 82 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:59:04,545]\u001b[0m Trial 83 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:59:16,803]\u001b[0m Trial 84 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:59:29,102]\u001b[0m Trial 85 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 17:59:41,384]\u001b[0m Trial 86 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 18:03:45,207]\u001b[0m Trial 87 finished with value: 0.6957206130027771 and parameters: {'optimizer': 'Adam', 'lr': 0.0014277182982882569}. Best is trial 21 with value: 0.7552627325057983.\u001b[0m\n",
      "\u001b[32m[I 2021-11-13 18:03:57,809]\u001b[0m Trial 88 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 18:04:10,346]\u001b[0m Trial 89 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 18:04:47,278]\u001b[0m Trial 90 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 18:04:59,769]\u001b[0m Trial 91 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 18:05:12,284]\u001b[0m Trial 92 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 18:05:24,592]\u001b[0m Trial 93 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 18:05:36,545]\u001b[0m Trial 94 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 18:05:48,884]\u001b[0m Trial 95 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 18:06:01,080]\u001b[0m Trial 96 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 18:07:01,416]\u001b[0m Trial 97 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 18:07:13,897]\u001b[0m Trial 98 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-11-13 18:07:26,302]\u001b[0m Trial 99 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  100\n",
      "  Number of pruned trials:  85\n",
      "  Number of complete trials:  15\n",
      "Best trial:\n",
      "  Value:  0.7552627325057983\n",
      "  Params: \n",
      "    optimizer: Adam\n",
      "    lr: 0.0009683390435270988\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aa9148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Network(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.input_dims = 3072\n",
    "#         self.layer1 = nn.Linear(in_features=3072, out_features=512)\n",
    "#         self.layer2 = nn.Linear(in_features=512, out_features=256)\n",
    "#         self.layer3 = nn.Linear(in_features=256, out_features=64)\n",
    "#         self.layer4 = nn.Linear(in_features=64, out_features=10)\n",
    "        \n",
    "#         self.relu1 = nn.ReLU(inplace=True)\n",
    "#         self.relu2 = nn.ReLU(inplace=True)\n",
    "#         self.relu3 = nn.ReLU(inplace=True)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.relu1(self.layer1(x))\n",
    "#         x = self.relu2(self.layer2(x))\n",
    "#         x = self.relu3(self.layer3(x))\n",
    "#         x = self.layer4(x)\n",
    "#         pred = F.log_softmax(x, dim=1)\n",
    "#         return x\n",
    "\n",
    "# model = Network()\n",
    "# model.to(device)\n",
    "# criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# lr = 1e-3\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# def training(Epochs=20):\n",
    "#     loss_list= []\n",
    "#     loss_hist  = []\n",
    "#     for epoch in range(Epochs):\n",
    "#         cur_loss_list = []\n",
    "#         progress_bar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "#         for i, (img, label) in progress_bar:\n",
    "#             img, label = img.to(device), label.type(torch.float32).to(device)\n",
    "\n",
    "#             pred = model.forward(img)\n",
    "\n",
    "#             loss = criterion(pred, label)\n",
    "#             cur_loss_list.append(loss.item())\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             if(i % 1 == 0):\n",
    "#                 progress_bar.set_description(f\"Epoch {epoch+1} Iter {i+1}: loss {loss.item():.5f}. \")\n",
    "        \n",
    "#         loss_list = loss_list + cur_loss_list        \n",
    "#         loss_hist.append(np.mean(cur_loss_list))\n",
    "#     return loss_list, loss_hist\n",
    "# training()\n",
    "\n",
    "# def testing(test_loader, net):\n",
    "#     with torch.no_grad():\n",
    "#         total_corr = 0\n",
    "#         for x, y in test_loader:\n",
    "# #             x, y = x.to(device), y.type(torch.float32).to(device)\n",
    "\n",
    "#             output = net.forward(x)\n",
    "\n",
    "#             pred = torch.argmax(torch.Tensor(output), dim=1)\n",
    "#             gt = torch.argmax(y, dim=1)\n",
    "#             correct = torch.count_nonzero(pred == gt)\n",
    "#             total_corr += correct\n",
    "#         return (total_corr/len(test_dataset))\n",
    "\n",
    "# testing(test_loader, model.to(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c019310",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
