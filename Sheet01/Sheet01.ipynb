{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40fe6d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac51dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = torch.squeeze(train_dataset[0][0])\n",
    "# fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "# ax.imshow(img, cmap=plt.cm.gray)\n",
    "%config Completer.use_jedi = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3873556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloader \n",
    "batch_size = 1\n",
    "train_loader = DataLoader(\n",
    "                dataset= train_dataset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False) \n",
    "test_loader = DataLoader(\n",
    "                dataset = test_dataset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eac1692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting dtype of the tensors\n",
    "class NeuralNet():\n",
    "    def __init__(self, LR, batch_size):\n",
    "        self.layer1 = np.random.uniform(-0.5, 0.5, (784, 64))\n",
    "        self.layer2 = np.random.uniform(-0.5, 0.5, (64, 10))\n",
    "        self.LR = LR\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def softmax(self, x):\n",
    "        denominator = torch.sum(np.exp(x), 1)\n",
    "        for i in range(len(x)):\n",
    "            x[i] = np.divide(x[i], denominator[i])\n",
    "        return x\n",
    "    \n",
    "    def non_linearity(self, x):\n",
    "        return (1 / (1 - np.exp(-1 * x)))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.squeeze(x).view(-1, 784)\n",
    "        self.input = x.clone()\n",
    "\n",
    "        x = x @ self.layer1\n",
    "        x = self.non_linearity(x)\n",
    "        self.z1 = x.clone()\n",
    "        x = x @ self.layer2\n",
    "        x = self.non_linearity(x)\n",
    "        x = self.softmax(x)\n",
    "        self.softmax_result = x.clone().float().T\n",
    "        return x\n",
    "    \n",
    "    def backpass(self, loss, outputs, gt):\n",
    "        d_loss_wrt_preds = (-2/torch.numel(outputs)) * (gt - outputs).float() \n",
    "        \n",
    "        delta_w1 = self.input.T @ d_loss_wrt_preds @ self.der_softmax() @ self.layer2.T\n",
    "\n",
    "        delta_w2 = self.z1.T.float() @ d_loss_wrt_preds.float() @ self.der_softmax().float() \n",
    "        \n",
    "        self.layer1 = torch.Tensor(self.layer1).float() - self.LR * delta_w1.float()\n",
    "        self.layer2 = torch.Tensor(self.layer2) - self.LR * delta_w2\n",
    "    \n",
    "    def der_softmax(self):\n",
    "        softmax_d = torch.empty(self.batch_size, len(self.softmax_result), len(self.softmax_result))\n",
    "        for elem in range()    \n",
    "            for i in range(softmax_d.shape[1]):\n",
    "                for j in range(softmax_d.shape[2]):\n",
    "                    if i == j:\n",
    "                        softmax_d[i, j] = self.softmax_result[i] * (1 - self.softmax_result[j])\n",
    "                    else:\n",
    "                        softmax_d[i, j] = -1 * self.softmax_result[i] * self.softmax_result[j]\n",
    "        return softmax_d\n",
    "    \n",
    "    def one_hot_encoding(self, y):\n",
    "        return F.one_hot(y, num_classes=10)\n",
    "    \n",
    "    def mean_sq_error(self, x, y):\n",
    "        error = torch.sum((x - y) **2) / torch.numel(x)\n",
    "        return error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9af4c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.01\n",
    "net = NeuralNet(LR, batch_size)\n",
    "def training(EPOCHS):\n",
    "    for epoch in range(EPOCHS):\n",
    "        for x,y in train_loader:\n",
    "            outputs = net.forward(x)\n",
    "\n",
    "            gt = net.one_hot_encoding(y)\n",
    "            batch_loss = net.mean_sq_error(outputs, gt)\n",
    "            \n",
    "            net.backpass(loss, outputs, gt)\n",
    "        total_loss = total_loss + batch_loss \n",
    "        print(f\"Loss for EPOCH={epoch} is {total_loss}\")\n",
    "\n",
    "training(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc8ec945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training \n",
    "\n",
    "# Testing\n",
    "def testing(test_loader, net):\n",
    "    for x, y in test_loader:\n",
    "        output = net.forward(x)\n",
    "        prediction = torch.argmax(output)\n",
    "        print(y, prediction)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3c9088e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 10])\n",
      "torch.Size([1, 10, 10])\n",
      "torch.Size([1, 10, 10])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected batch2_sizes[0] == bs && batch2_sizes[1] == contraction_size to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17879/3107688382.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_17879/619278216.py\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(EPOCHS)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_sq_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loss for EPOCH={epoch} is {total_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_17879/1500600095.py\u001b[0m in \u001b[0;36mbackpass\u001b[0;34m(self, loss, outputs, gt)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0md_loss_wrt_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mdelta_w1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0md_loss_wrt_preds\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mder_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mdelta_w2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0md_loss_wrt_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mder_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected batch2_sizes[0] == bs && batch2_sizes[1] == contraction_size to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc781027",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing(test_loader, net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
