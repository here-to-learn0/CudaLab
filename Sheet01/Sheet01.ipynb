{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40fe6d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dac51dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = torch.squeeze(train_dataset[0][0])\n",
    "# fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "# ax.imshow(img, cmap=plt.cm.gray)\n",
    "%config Completer.use_jedi = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3873556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloader \n",
    "batch_size = 20\n",
    "train_loader = DataLoader(\n",
    "                dataset= train_dataset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False) \n",
    "test_loader = DataLoader(\n",
    "                dataset = test_dataset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "eac1692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting dtype of the tensors\n",
    "class NeuralNet():\n",
    "    def __init__(self, LR, batch_size):\n",
    "        self.layer1 = np.random.uniform(-0.5, 0.5, (784, 64)).astype(np.float64)\n",
    "        self.layer2 = np.random.uniform(-0.5, 0.5, (64, 10)).astype(np.float64)\n",
    "        self.LR = LR\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def softmax(self, x):\n",
    "        denominators = torch.sum(np.exp(x), 1)\n",
    "        for i in range(len(x)):\n",
    "            x[i] = np.divide(x[i], denominators[i])\n",
    "        return x\n",
    "    \n",
    "    def non_linearity(self, x):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.squeeze(x).view(-1, 784)\n",
    "        self.input = x.clone()\n",
    "\n",
    "        x = x @ self.layer1\n",
    "        x = self.non_linearity(x)\n",
    "        \n",
    "        self.z1 = x.clone()\n",
    "        x = x @ self.layer2\n",
    "        \n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        self.softmax_result = x.clone().float().T\n",
    "        return x\n",
    "    \n",
    "    def der_sigmoid(self, x):\n",
    "        return (x @ (1 - x).T).float()\n",
    "        \n",
    "    def backpass(self, loss, outputs, gt):\n",
    "        d_loss_wrt_preds = (-2/torch.numel(outputs)) * (gt - outputs)\n",
    "        \n",
    "        delta_w1 = self.input.T @ self.der_sigmoid(self.z1) @ d_loss_wrt_preds.float() @ self.der_softmax() @ self.layer2.T \n",
    "        delta_w2 = self.z1.T.float() @ d_loss_wrt_preds.float() @ self.der_softmax().float() \n",
    "        \n",
    "        self.layer1 = torch.Tensor(self.layer1).float() - self.LR * delta_w1.float()\n",
    "        self.layer2 = torch.Tensor(self.layer2) - self.LR * delta_w2\n",
    "\n",
    "    \n",
    "    def der_softmax(self):\n",
    "        softmax_d = torch.empty(self.batch_size, len(self.softmax_result), len(self.softmax_result))\n",
    "        \n",
    "        for elem in range(self.batch_size):    \n",
    "            for i in range(softmax_d.shape[1]):\n",
    "                for j in range(softmax_d.shape[2]):\n",
    "                    if i == j:\n",
    "                        softmax_d[elem, i, j] = self.softmax_result.T[elem, i] * (1 - self.softmax_result.T[elem, j])\n",
    "                    \n",
    "                    else:\n",
    "                        softmax_d[elem, i, j] = -1 * self.softmax_result.T[elem, i] * self.softmax_result.T[elem, j]\n",
    "        return torch.sum(softmax_d, 0).float()\n",
    "    \n",
    "    def one_hot_encoding(self, y):\n",
    "        return F.one_hot(y, num_classes=10)\n",
    "    \n",
    "    def mean_sq_error(self, x, y):\n",
    "        error = torch.sum((x - y) **2) / torch.numel(x)\n",
    "        return error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af4c2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20286/1028899167.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for EPOCH=0 is 0.1007891595363617\n",
      "Loss for EPOCH=1 is 0.20118889212608337\n",
      "Loss for EPOCH=2 is 0.30145588517189026\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "def training(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    for epoch in range(EPOCHS):\n",
    "        for x,y in train_loader:\n",
    "            \n",
    "            outputs = net.forward(x)\n",
    "            gt = net.one_hot_encoding(y)\n",
    "            batch_loss = net.mean_sq_error(outputs, gt)\n",
    "#             print(batch_loss)\n",
    "            net.backpass(batch_loss, outputs, gt)\n",
    "\n",
    "        total_loss = total_loss + batch_loss \n",
    "        print(f\"Loss for EPOCH={epoch} is {total_loss}\")\n",
    "\n",
    "# Testing\n",
    "def testing(test_loader, net):\n",
    "    for x, y in test_loader:\n",
    "        output = net.forward(x)\n",
    "        prediction = torch.argmax(output)\n",
    "        print(y, prediction)\n",
    "        break\n",
    "\n",
    "LR = 0.01\n",
    "net = NeuralNet(LR, batch_size)\n",
    "training(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096e61ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af80bc80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
