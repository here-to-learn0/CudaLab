{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40fe6d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac51dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([transforms.ToTensor(), \n",
    "                        transforms.Lambda(lambda img: img.squeeze().reshape(784))])\n",
    "\n",
    "trans_target = lambda label: F.one_hot(torch.tensor(label), num_classes=10)\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transformations , target_transform=trans_target)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transformations , target_transform=trans_target)\n",
    "# fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "# ax.imshow(img, cmap=plt.cm.gray)\n",
    "%config Completer.use_jedi = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fb96a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label for this image is: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the images and lables\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(15,5)\n",
    "\n",
    "img = train_dataset[0][0].numpy().reshape(28, 28)\n",
    "im = ax.imshow(img, cmap=plt.cm.gray)\n",
    "fig.colorbar(im)\n",
    "ax.set_title(\"Image\")\n",
    "print(f\"The label for this image is: {train_dataset[0][1].argmax()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3873556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloader \n",
    "batch_size = 20\n",
    "train_loader = DataLoader(\n",
    "                dataset= train_dataset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False) \n",
    "test_loader = DataLoader(\n",
    "                dataset = test_dataset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eac1692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet():\n",
    "    def __init__(self, LR, batch_size):\n",
    "        np.random.seed(0)\n",
    "\n",
    "        self.layer1 = np.random.uniform(-0.5, 0.5, (784, 64))\n",
    "        self.layer2 = np.random.uniform(-0.5, 0.5, (64, 10))\n",
    "        self.bias1 = np.zeros((1, 64))\n",
    "        self.bias2 = np.zeros((1,10))\n",
    "        self.batch_size = batch_size\n",
    "        self.LR = LR\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "\n",
    "    def softmax(self, z):\n",
    "        ez = np.exp(z/z.max())\n",
    "        sum_ez = np.sum(ez, axis=0)\n",
    "        return ez / (sum_ez)    \n",
    "    \n",
    "    def d_sigmoid(self, x):\n",
    "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
    "    \n",
    "    def d_softmax(self, a, y):\n",
    "        result = np.sum((a-y).T * (np.diag(a.squeeze()) - np.multiply(a, a.T)), axis=1)\n",
    "        return result\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.m1 = np.dot(x, self.layer1) + self.bias1\n",
    "        self.z1 = self.sigmoid(self.m1)\n",
    "        self.z2 = np.dot(self.z1, self.layer2) + self.bias2\n",
    "        self.y_pred = self.softmax(self.z2)\n",
    "        return self.y_pred\n",
    "    \n",
    "    def backpass(self, y):\n",
    "        d_pred = np.empty((self.batch_size, 10))\n",
    "        for i in range(self.batch_size):\n",
    "            d_pred[i] = self.d_softmax(self.y_pred[i], y[i])\n",
    "        \n",
    "        d_m1 = self.d_sigmoid(self.m1) * (np.dot(d_pred, self.layer2.T))\n",
    "        d_layer1 = 1/self.batch_size * np.dot(self.x.T, d_m1)\n",
    "        d_layer2 = 1/self.batch_size * np.dot(self.z1.T, d_pred)\n",
    "#         d_bias1 = 1/self.batch_size * (self.x @ self.layer1)* d_m1\n",
    "#         d_bias2 = 1/self.batch_size * (self.z1 @ self.layer2) * d_pred\n",
    "        \n",
    "#         assert d_bias1.shape == (self.batch_size, 64)\n",
    "#         assert d_bias2.shape == (self.batch_size, 10)\n",
    "        \n",
    "        self.layer1 = self.layer1 - self.LR * d_layer1\n",
    "        self.layer2 = self.layer2 - self.LR * d_layer2\n",
    "#         self.bias1 = self.bias1 - self.LR * d_bias1\n",
    "#         self.bias2 = self.bias2 - self.LR * d_bias2\n",
    "        \n",
    "    \n",
    "    def mse(self, y, pred):\n",
    "        return np.sum(np.sum((pred - y)**2, axis=1))/self.batch_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9af4c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def training(EPOCHS = 500, print_every=25):\n",
    "    loss_list = []\n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "        total_loss = 0.0\n",
    "        for x,y in train_loader:\n",
    "            x,y = x.numpy(), y.numpy()\n",
    "            pred = net.forward(x)\n",
    "\n",
    "            loss = net.mse(y, pred)\n",
    "            \n",
    "            net.backpass(y)\n",
    "            total_loss += loss\n",
    "        loss_list.append(total_loss)\n",
    "        \n",
    "        if (epoch+1) % print_every == 0 or epoch == 0:\n",
    "            print(f\"Epoch {epoch + 1} has loss {total_loss}\")\n",
    "    return loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fc25f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                         | 1/500 [00:07<1:05:36,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 has loss 2740.3569528552644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                        | 25/500 [03:07<57:01,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 has loss 2696.932893172238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▏                                     | 50/500 [06:12<56:10,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 has loss 2691.493707132148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████▎                                   | 75/500 [09:13<50:02,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 has loss 2689.0156091933454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▏                                | 100/500 [12:14<49:00,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 has loss 2687.5069720298306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████▎                              | 125/500 [15:24<47:37,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125 has loss 2686.4804618536173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▎                            | 150/500 [18:30<43:28,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150 has loss 2685.7226064102165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████▎                          | 175/500 [21:35<40:26,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175 has loss 2685.1394789726173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████▍                        | 200/500 [24:39<36:55,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200 has loss 2684.665888921953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████▍                      | 225/500 [27:45<34:08,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225 has loss 2684.265383154756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████▌                    | 250/500 [30:50<30:41,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250 has loss 2683.9203360197307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████████████▌                  | 275/500 [33:57<27:56,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275 has loss 2683.6228633675173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████▌                | 300/500 [37:02<25:07,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300 has loss 2683.364808038063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████████████████████████▋              | 325/500 [40:05<21:01,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 325 has loss 2683.1360795560036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████▋            | 350/500 [43:06<18:12,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350 has loss 2682.9293978200426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████▊          | 375/500 [46:08<15:14,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 375 has loss 2682.741109648585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████▊        | 400/500 [49:08<12:04,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400 has loss 2682.573903183264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|██████████████████████████████████▊      | 425/500 [52:11<09:04,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425 has loss 2682.4151455044666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████▉    | 450/500 [55:14<06:03,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450 has loss 2682.265117943924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|██████████████████████████████████████▉  | 475/500 [58:15<03:01,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475 has loss 2682.1273545553377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 500/500 [1:01:17<00:00,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500 has loss 2682.0002170895723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "LR = 0.1\n",
    "net = NeuralNet(LR, batch_size)\n",
    "loss_list = training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af80bc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "def testing(test_loader, net):\n",
    "    total_corr = 0\n",
    "    for x, y in test_loader:\n",
    "        output = net.forward(x)\n",
    "\n",
    "        pred = torch.argmax(torch.Tensor(output), dim=1)\n",
    "        gt = torch.argmax(y, axis=1)\n",
    "\n",
    "        correct = torch.count_nonzero(pred == gt)\n",
    "        total_corr += correct\n",
    "\n",
    "    return (total_corr/len(test_dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
