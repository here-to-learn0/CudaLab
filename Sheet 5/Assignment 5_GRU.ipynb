{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce8731ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "124b394f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "\n",
    "    def __init__(self, in_sz, hid_sz, bias=True):\n",
    "        super(GRU, self).__init__()\n",
    "        self.in_sz = in_sz\n",
    "        self.hid_sz = hid_sz\n",
    "        self.bias = bias\n",
    "        self.layer1 = nn.Linear(in_sz, 3 * hid_sz, bias=bias)\n",
    "        self.layer2 = nn.Linear(hid_sz, 3 * hid_sz, bias=bias)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        std = 1.0 / math.sqrt(self.hid_sz)\n",
    "        for w in self.parameters():\n",
    "            w.data.uniform_(-std, std)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "\n",
    "        x = x.view(-1, x.size(1))\n",
    "\n",
    "        gate_x = self.layer1(x) \n",
    "        gate_h = self.layer2(hidden)\n",
    "\n",
    "        gate_x = gate_x.squeeze()\n",
    "        gate_h = gate_h.squeeze()\n",
    "        i_r, i_i, i_n = gate_x.chunk(3, 1)\n",
    "        h_r, h_i, h_n = gate_h.chunk(3, 1)\n",
    "\n",
    "\n",
    "        reset_gate = torch.sigmoid(i_r + h_r)\n",
    "        input_gate = torch.sigmoid(i_i + h_i)\n",
    "        next_gate = torch.tanh(i_n + (reset_gate * h_n))\n",
    "\n",
    "        hy = next_gate + input_gate * (hidden - next_gate)\n",
    "\n",
    "        return hy\n",
    "\n",
    "#create GRU model class\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, bias=True):\n",
    "        super(GRUModel, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.gru = GRU(input_dim, hidden_dim, layer_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        if torch.cuda.is_available():\n",
    "            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda())\n",
    "        else:\n",
    "            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "       \n",
    "        outs = []\n",
    "        \n",
    "        hn = h0[0,:,:]\n",
    "        #for 28 time steps\n",
    "        for seq in range(x.size(1)):\n",
    "            hn = self.gru(x[:,seq,:], hn) \n",
    "            outs.append(hn)\n",
    "            \n",
    "        # Index hidden state of last time step\n",
    "        out = outs[-1].squeeze()\n",
    "        \n",
    "        out = self.fc(out) \n",
    "        # out.size() --> 100, 10\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c460e250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading and Loading Dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(),download=True)\n",
    " \n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bc41616",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_SIZE = 256\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=B_SIZE, \n",
    "                                           shuffle=True) \n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=B_SIZE,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db25d120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, criterion, epoch, device,seq_dim):\n",
    "    \"\"\" Training a model for one epoch \"\"\"\n",
    "    \n",
    "    loss_list = []\n",
    "    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for i, (images, labels) in progress_bar:\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
    "        else:\n",
    "            images = Variable(images.view(-1 , seq_dim, input_dim))\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "                    \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "         \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "         \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_list.append(loss.item())\n",
    "         \n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "         \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        progress_bar.set_description(f\"Epoch {epoch+1} Iter {i+1}: loss {loss.item():.5f}. \")\n",
    "        \n",
    "    mean_loss = np.mean(loss_list)\n",
    "    return mean_loss, loss_list\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_model(model, eval_loader, criterion, device,seq_dim):\n",
    "    \"\"\" Evaluating the model for either validation or test \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_list = []\n",
    "    \n",
    "    for i, (images, labels) in enumerate(eval_loader):\n",
    "          \n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        \n",
    "        # Forward pass only to get logits/output\n",
    "        outputs = model(images)\n",
    "                 \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_list.append(loss.item())\n",
    "            \n",
    "        # Get predictions from the maximum value\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        correct += len( torch.where(preds==labels)[0] )\n",
    "        total += len(labels)\n",
    "                 \n",
    "    # Total correct predictions and loss\n",
    "    accuracy = correct / total * 100\n",
    "    loss = np.mean(loss_list)\n",
    "    \n",
    "    return accuracy, loss\n",
    "\n",
    "\n",
    "def train_model(model, optimizer, scheduler, criterion, train_loader, valid_loader, num_epochs,seq_dim):\n",
    "    \"\"\" Training a model for a given number of epochs\"\"\"\n",
    "    \n",
    "    train_loss = []\n",
    "    val_loss =  []\n",
    "    loss_iters = []\n",
    "    valid_acc = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "           \n",
    "        # validation epoch\n",
    "        model.eval()  # important for dropout and batch norms\n",
    "        accuracy, loss = eval_model(\n",
    "                    model=model, eval_loader=valid_loader,\n",
    "                    criterion=criterion, device=device,seq_dim=seq_dim\n",
    "            )\n",
    "        valid_acc.append(accuracy)\n",
    "        val_loss.append(loss)\n",
    "        \n",
    "        # training epoch\n",
    "        model.train()  # important for dropout and batch norms\n",
    "        mean_loss, cur_loss_iters = train_epoch(\n",
    "                model=model, train_loader=train_loader, optimizer=optimizer,\n",
    "                criterion=criterion, epoch=epoch, device=device,seq_dim=seq_dim\n",
    "            )\n",
    "        scheduler.step()\n",
    "        train_loss.append(mean_loss)\n",
    "        loss_iters = loss_iters + cur_loss_iters\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"    Train loss: {round(mean_loss, 5)}\")\n",
    "        print(f\"    Valid loss: {round(loss, 5)}\")\n",
    "        print(f\"    Accuracy: {accuracy}%\")\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    print(f\"Training completed\")\n",
    "    return train_loss, val_loss, loss_iters, valid_acc\n",
    "\n",
    "\n",
    "def smooth(f, K=5):\n",
    "    \"\"\" Smoothing a function using a low-pass filter (mean) of size K \"\"\"\n",
    "    kernel = np.ones(K) / K\n",
    "    f = np.concatenate([f[:int(K//2)], f, f[int(-K//2):]])  # to account for boundaries\n",
    "    smooth_f = np.convolve(f, kernel, mode=\"same\")\n",
    "    smooth_f = smooth_f[K//2: -K//2]  # removing boundary-fixes\n",
    "    return smooth_f\n",
    "\n",
    "def count_model_params(model):\n",
    "    \"\"\" Counting the number of learnable parameters in a nn.Module \"\"\"\n",
    "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f2365c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daf6ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 28\n",
    "hidden_dim = 128\n",
    "layer_dim = 1  \n",
    "output_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e1db12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GRU = GRUModel(input_dim, hidden_dim, layer_dim, output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "788bfc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRUModel(\n",
      "  (gru): GRU(\n",
      "    (layer1): Linear(in_features=28, out_features=384, bias=True)\n",
      "    (layer2): Linear(in_features=128, out_features=384, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_GRU = model_GRU.to(device)\n",
    "print(model_GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5dee199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = torch.optim.Adam(model_GRU.parameters(), lr=3e-4)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 5 epochs\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57657437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Iter 235: loss 1.10431. : 100%|██████████████████████████████████████████████| 235/235 [00:40<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "    Train loss: 1.55078\n",
      "    Valid loss: 2.30515\n",
      "    Accuracy: 9.4%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Iter 235: loss 0.49073. : 100%|██████████████████████████████████████████████| 235/235 [00:40<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "    Train loss: 0.69174\n",
      "    Valid loss: 0.83831\n",
      "    Accuracy: 72.41%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Iter 235: loss 0.51085. : 100%|██████████████████████████████████████████████| 235/235 [00:40<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "    Train loss: 0.49299\n",
      "    Valid loss: 0.56083\n",
      "    Accuracy: 81.82000000000001%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Iter 235: loss 0.45847. : 100%|██████████████████████████████████████████████| 235/235 [00:40<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "    Train loss: 0.36696\n",
      "    Valid loss: 0.41034\n",
      "    Accuracy: 87.31%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Iter 235: loss 0.29104. : 100%|██████████████████████████████████████████████| 235/235 [00:40<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "    Train loss: 0.28554\n",
      "    Valid loss: 0.30923\n",
      "    Accuracy: 90.62%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Iter 235: loss 0.24356. : 100%|██████████████████████████████████████████████| 235/235 [00:40<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "    Train loss: 0.24216\n",
      "    Valid loss: 0.24634\n",
      "    Accuracy: 92.62%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Iter 235: loss 0.29799. : 100%|██████████████████████████████████████████████| 235/235 [00:39<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "    Train loss: 0.2316\n",
      "    Valid loss: 0.22904\n",
      "    Accuracy: 93.37%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Iter 235: loss 0.26963. : 100%|██████████████████████████████████████████████| 235/235 [00:41<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "    Train loss: 0.22243\n",
      "    Valid loss: 0.22043\n",
      "    Accuracy: 93.47999999999999%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Iter 235: loss 0.21602. : 100%|██████████████████████████████████████████████| 235/235 [00:40<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "    Train loss: 0.21378\n",
      "    Valid loss: 0.21149\n",
      "    Accuracy: 93.75%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Iter 235: loss 0.20722. : 100%|█████████████████████████████████████████████| 235/235 [00:40<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "    Train loss: 0.20486\n",
      "    Valid loss: 0.20214\n",
      "    Accuracy: 93.99%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Iter 235: loss 0.25198. : 100%|█████████████████████████████████████████████| 235/235 [00:39<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "    Train loss: 0.19867\n",
      "    Valid loss: 0.19535\n",
      "    Accuracy: 94.31%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 Iter 235: loss 0.18078. : 100%|█████████████████████████████████████████████| 235/235 [00:40<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "    Train loss: 0.19671\n",
      "    Valid loss: 0.19232\n",
      "    Accuracy: 94.31%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 Iter 235: loss 0.12293. : 100%|█████████████████████████████████████████████| 235/235 [00:39<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "    Train loss: 0.19498\n",
      "    Valid loss: 0.19101\n",
      "    Accuracy: 94.36%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 Iter 235: loss 0.25450. : 100%|█████████████████████████████████████████████| 235/235 [00:39<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "    Train loss: 0.19379\n",
      "    Valid loss: 0.18945\n",
      "    Accuracy: 94.45%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 Iter 235: loss 0.30398. : 100%|█████████████████████████████████████████████| 235/235 [00:39<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "    Train loss: 0.1923\n",
      "    Valid loss: 0.1879\n",
      "    Accuracy: 94.5%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 Iter 235: loss 0.21057. : 100%|█████████████████████████████████████████████| 235/235 [00:40<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "    Train loss: 0.1908\n",
      "    Valid loss: 0.1866\n",
      "    Accuracy: 94.61%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 Iter 235: loss 0.25099. : 100%|█████████████████████████████████████████████| 235/235 [00:40<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "    Train loss: 0.19056\n",
      "    Valid loss: 0.18614\n",
      "    Accuracy: 94.58%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 Iter 235: loss 0.09525. : 100%|█████████████████████████████████████████████| 235/235 [00:40<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "    Train loss: 0.18981\n",
      "    Valid loss: 0.18587\n",
      "    Accuracy: 94.6%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 Iter 235: loss 0.24636. : 100%|█████████████████████████████████████████████| 235/235 [00:39<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "    Train loss: 0.18992\n",
      "    Valid loss: 0.18557\n",
      "    Accuracy: 94.6%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 Iter 235: loss 0.11437. : 100%|█████████████████████████████████████████████| 235/235 [00:39<00:00,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "    Train loss: 0.18927\n",
      "    Valid loss: 0.18529\n",
      "    Accuracy: 94.58%\n",
      "\n",
      "\n",
      "Training completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss, loss_iters, valid_acc = train_model(\n",
    "        model=model_GRU, optimizer=optimizer, scheduler=scheduler, criterion=criterion,\n",
    "        train_loader=train_loader, valid_loader=test_loader, num_epochs=20,seq_dim=28\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8e5c7816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a816b2d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
